{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deburky/boosting-scorecards/blob/main/other_notebooks/xbooster-chi-square-validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a232cb23-f5b9-417f-82ee-45f2c5fb8b9b",
      "metadata": {
        "id": "a232cb23-f5b9-417f-82ee-45f2c5fb8b9b"
      },
      "source": [
        "# <span style=\"font-family: Arial, sans-serif; color:#97f788\">xbooster</span>\n",
        "## <span style=\"font-family: Arial, sans-serif; color:navyblue\">Validation with Ï‡2</span>\n",
        "\n",
        "<span style=\"font-family: Arial, sans-serif; color:navyblue\">Repo: <a href=\"https://github.com/xRiskLab/xBooster\" title=\"GitHub link\">https://github.com/xRiskLab/xBooster</a></span>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install xbooster"
      ],
      "metadata": {
        "id": "-jckHR40HiYz"
      },
      "id": "-jckHR40HiYz",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "print(version(\"xbooster\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3jMMlSPHkS5",
        "outputId": "645efef6-6577-41e5-a64a-0c8ff62497ce"
      },
      "id": "c3jMMlSPHkS5",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4c7e18b6-4f82-46e4-a2f7-d840f7a1a939",
      "metadata": {
        "id": "4c7e18b6-4f82-46e4-a2f7-d840f7a1a939"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Fetch blended credit data\n",
        "url = (\n",
        "    \"https://github.com/xRiskLab/xBooster/raw/main/examples/data/credit_data.parquet\"\n",
        ")\n",
        "dataset = pd.read_parquet(url)\n",
        "\n",
        "features = [\n",
        "    \"external_risk_estimate\",\n",
        "    \"revolving_utilization_of_unsecured_lines\",\n",
        "    \"account_never_delinq_percent\",\n",
        "    \"net_fraction_revolving_burden\",\n",
        "    \"num_total_cc_accounts\",\n",
        "    \"average_months_in_file\",\n",
        "]\n",
        "\n",
        "target = \"is_bad\"\n",
        "\n",
        "X, y = dataset[features], dataset[target]\n",
        "\n",
        "ix_train, ix_test = train_test_split(\n",
        "    X.index, stratify=y, test_size=0.3, random_state=62\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "RY6LT0hVKOjV"
      },
      "id": "RY6LT0hVKOjV"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "50db8167-80e9-41c1-a1ef-72682742828f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50db8167-80e9-41c1-a1ef-72682742828f",
        "outputId": "94ea9e50-283c-478c-a6dd-f433d59494c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Gini score: 89.84%\n",
            "Test Gini score: 89.11%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "best_params = dict(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.55,\n",
        "    max_depth=1,\n",
        "    min_child_weight=10,\n",
        "    grow_policy=\"lossguide\",\n",
        "    early_stopping_rounds=5,\n",
        ")\n",
        "\n",
        "# Create an XGBoost model\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    **best_params, random_state=62\n",
        ")\n",
        "evalset = [\n",
        "    (X.loc[ix_train], y.loc[ix_train]),\n",
        "    (X.loc[ix_test], y.loc[ix_test]),\n",
        "]\n",
        "\n",
        "# Fit the XGBoost model\n",
        "xgb_model.fit(\n",
        "    X.loc[ix_train],\n",
        "    y.loc[ix_train],\n",
        "    eval_set=evalset,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "# Make predictions using the model\n",
        "predictions_trn = xgb_model.predict_proba(X.loc[ix_train])[\n",
        "    :, 1\n",
        "]\n",
        "predictions_tst = xgb_model.predict_proba(X.loc[ix_test])[\n",
        "    :, 1\n",
        "]\n",
        "\n",
        "# Calculate the Gini score\n",
        "gini_trn = roc_auc_score(y.loc[ix_train], predictions_trn) * 2 - 1  # type: ignore\n",
        "gini_tst = roc_auc_score(y.loc[ix_test], predictions_tst) * 2 - 1  # type: ignore\n",
        "\n",
        "print(\n",
        "    f\"Train Gini score: {gini_trn:.2%}\\n\"\n",
        "    f\"Test Gini score: {gini_tst:.2%}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "from xbooster.constructor import XGBScorecardConstructor\n",
        "\n",
        "# Set up the scorecard constructor\n",
        "scorecard_constructor = XGBScorecardConstructor(\n",
        "    xgb_model, X.loc[ix_train], y.loc[ix_train]\n",
        ")\n",
        "\n",
        "# Construct the scorecard\n",
        "xgb_scorecard = scorecard_constructor.construct_scorecard()\n",
        "\n",
        "xgb_scorecard_with_points = (\n",
        "    scorecard_constructor.create_points(\n",
        "        pdo=50, target_points=600, target_odds=50\n",
        "    )\n",
        ")\n",
        "\n",
        "# Make predictions using the scorecard\n",
        "credit_scores = scorecard_constructor.predict_score(\n",
        "    X.loc[ix_test]\n",
        ")\n",
        "gini = roc_auc_score(y.loc[ix_test], -credit_scores) * 2 - 1  # type: ignore\n",
        "\n",
        "print(f\"Test Gini score: {gini:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pirEbb5aKSVD",
        "outputId": "2ac61fe3-96f1-454b-8c6e-565bd0f9c4c6"
      },
      "id": "pirEbb5aKSVD",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Gini score: 89.09%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_select = [\n",
        "    'Tree',\n",
        "    'Node',\n",
        "    'Feature',\n",
        "    'Sign',\n",
        "    'Split',\n",
        "    'Events',\n",
        "    'NonEvents',\n",
        "]\n",
        "\n",
        "xgb_train_summary = xgb_scorecard_with_points[cols_to_select].copy()"
      ],
      "metadata": {
        "id": "WjMrVIB2KcUu"
      },
      "id": "WjMrVIB2KcUu",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model validation"
      ],
      "metadata": {
        "id": "5LA1Dmq1KgQu"
      },
      "id": "5LA1Dmq1KgQu"
    },
    {
      "cell_type": "code",
      "source": [
        "# Add noise to X_test\n",
        "def add_noise(data, noise_level=0.1):\n",
        "    noisy_data = data.copy()\n",
        "    for column in noisy_data.columns:\n",
        "        noise = np.random.normal(0, noise_level, size=noisy_data[column].shape)\n",
        "        noisy_data[column] -= noise\n",
        "    return noisy_data\n",
        "\n",
        "# Slightly perturb the target values\n",
        "def perturb_target(target, perturbation_rate=0.1):\n",
        "    perturbed_target = target.copy()\n",
        "    n_perturb = int(len(target) * perturbation_rate)\n",
        "    perturb_indices = np.random.choice(target.index, n_perturb, replace=False)\n",
        "    perturbed_target.loc[perturb_indices] = 1 - perturbed_target.loc[perturb_indices]\n",
        "    return perturbed_target\n",
        "\n",
        "# Adding noise to X_test\n",
        "noise_level = 2.5\n",
        "\n",
        "dataset_for_validation = pd.concat([X.loc[ix_test], y.loc[ix_test]], axis=1)\n",
        "\n",
        "X_test_noisy = add_noise(dataset_for_validation[features], noise_level).reset_index(drop=True)\n",
        "y_test_noisy = perturb_target(dataset_for_validation[target], 0.01).reset_index(drop=True)\n",
        "\n",
        "# Combining the noisy X_test with y_test\n",
        "dataset_for_validation_noisy = pd.concat([X_test_noisy, y_test_noisy], axis=1)"
      ],
      "metadata": {
        "id": "4mTptdmhKcwN"
      },
      "id": "4mTptdmhKcwN",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "from xbooster.constructor import XGBScorecardConstructor\n",
        "\n",
        "# Set up the scorecard constructor\n",
        "scorecard_constructor_val = XGBScorecardConstructor(\n",
        "    xgb_model, dataset_for_validation_noisy[features], dataset_for_validation_noisy[target]\n",
        ")\n",
        "\n",
        "# Construct the scorecard\n",
        "xgb_scorecard_val = scorecard_constructor_val.construct_scorecard()\n",
        "\n",
        "xgb_scorecard_with_points_val = (\n",
        "    scorecard_constructor_val.create_points(\n",
        "        pdo=50, target_points=600, target_odds=50\n",
        "    )\n",
        ")\n",
        "\n",
        "# Make predictions using the scorecard\n",
        "credit_scores = scorecard_constructor_val.predict_score(\n",
        "    dataset_for_validation_noisy[features]\n",
        ")\n",
        "gini = roc_auc_score(dataset_for_validation_noisy[target], -credit_scores) * 2 - 1  # type: ignore\n",
        "\n",
        "print(f\"Test Gini score: {gini:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqu_prF_Ko2E",
        "outputId": "d5a3cc9a-5a17-44fa-a8ab-cf307dc863e4"
      },
      "id": "cqu_prF_Ko2E",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Gini score: 62.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_select = [\n",
        "    'Tree',\n",
        "    'Node',\n",
        "    'Feature',\n",
        "    'Sign',\n",
        "    'Split',\n",
        "    'Events',\n",
        "    'NonEvents',\n",
        "]\n",
        "\n",
        "xgb_val_summary = xgb_scorecard_with_points_val[cols_to_select].copy()"
      ],
      "metadata": {
        "id": "1nxZ4s69Kq7q"
      },
      "id": "1nxZ4s69Kq7q",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ï‡2 test"
      ],
      "metadata": {
        "id": "hfdFqZnRKtLr"
      },
      "id": "hfdFqZnRKtLr"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "def calculate_chi_square_statistic(df, lambda_=2):\n",
        "    tree_chi_sq = {'Tree': [], 'Chi-Square': [], 'P-Value': [], 'N_Nodes': []}\n",
        "\n",
        "    for tree in df['Tree'].unique():\n",
        "        tree_df = df[df['Tree'] == tree]\n",
        "\n",
        "        # Creating a contingency table from the dataframe\n",
        "        contingency_table = tree_df[['Events', 'NonEvents']].values\n",
        "\n",
        "        # Row sums and column sums\n",
        "        row_sums = contingency_table.sum(axis=1, keepdims=True)\n",
        "        col_sums = contingency_table.sum(axis=0, keepdims=True)\n",
        "        total = contingency_table.sum()\n",
        "\n",
        "        # Expected frequencies\n",
        "        expected = row_sums @ col_sums / total\n",
        "\n",
        "        # Chi-square statistic\n",
        "        chi_square_matrix = (contingency_table - expected) ** 2 / expected\n",
        "        chi_square = chi_square_matrix.sum()\n",
        "\n",
        "        # Penalty for complexity\n",
        "        n_leaves = len(tree_df['Node'].unique())\n",
        "        depth = int(np.log2(n_leaves))\n",
        "        complexity = (n_leaves - 1) * (depth - 1)\n",
        "\n",
        "        if n_leaves > 2:\n",
        "            chi_square_adj = chi_square / (1 + lambda_ * complexity)\n",
        "        else:\n",
        "            chi_square_adj = chi_square\n",
        "\n",
        "        # Degrees of freedom\n",
        "        r, c = contingency_table.shape\n",
        "        degrees_of_freedom = (r - 1) * (c - 1)\n",
        "\n",
        "        p_value = stats.chi2.sf(chi_square_adj, df=degrees_of_freedom)\n",
        "\n",
        "        # Store the results\n",
        "        tree_chi_sq['Tree'].append(tree)\n",
        "        tree_chi_sq['Chi-Square'].append(chi_square)\n",
        "        tree_chi_sq['P-Value'].append(p_value)\n",
        "        tree_chi_sq['N_Nodes'].append(len(tree_df))\n",
        "\n",
        "    return tree_chi_sq\n",
        "\n",
        "def analyze_chi_square_statistics(summary_df, dataset_name):\n",
        "    # Calculate chi-square statistics\n",
        "    chi_square_results = calculate_chi_square_statistic(summary_df)\n",
        "    df_results = pd.DataFrame(chi_square_results)\n",
        "\n",
        "    # Calculate total degrees of freedom\n",
        "    total_degrees_of_freedom = 0\n",
        "    for tree in summary_df['Tree'].unique():\n",
        "        tree_df = summary_df[summary_df['Tree'] == tree]\n",
        "        contingency_table = tree_df[['Events', 'NonEvents']].values\n",
        "        r, c = contingency_table.shape\n",
        "        total_degrees_of_freedom += (r - 1) * (c - 1)\n",
        "\n",
        "    # Calculate average chi-square\n",
        "    avg_chi_square = df_results['Chi-Square'].mean()\n",
        "    print(f\"{dataset_name} - Average Chi-Square: {avg_chi_square:.2f}\")\n",
        "\n",
        "    # Calculate p-value for the average chi-square\n",
        "    p_value_avg_chi_square = stats.chi2.sf(avg_chi_square, df=total_degrees_of_freedom)\n",
        "    print(f\"{dataset_name} - p-value of the average Chi-Square: {p_value_avg_chi_square:.5f}\")\n",
        "\n",
        "    # Calculate number of non-significant nodes\n",
        "    number_non_significant = (df_results['P-Value'] > 0.05).sum()\n",
        "    print(f\"{dataset_name} - Percent of non-significant trees: {number_non_significant / len(df_results):.2%}\\n\")"
      ],
      "metadata": {
        "id": "n1xBqQR3Ksnh"
      },
      "id": "n1xBqQR3Ksnh",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze chi-square results for training data\n",
        "analyze_chi_square_statistics(xgb_train_summary, \"Training Data\")\n",
        "\n",
        "# Analyze chi-square results for validation data\n",
        "analyze_chi_square_statistics(xgb_val_summary, \"Validation Data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yWKr_oKKz1q",
        "outputId": "a20836a9-9be4-478a-ab2b-a008552b2fc0"
      },
      "id": "2yWKr_oKKz1q",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data - Average Chi-Square: 280.06\n",
            "Training Data - p-value of the average Chi-Square: 0.00000\n",
            "Training Data - Percent of non-significant trees: 12.94%\n",
            "\n",
            "Validation Data - Average Chi-Square: 55.48\n",
            "Validation Data - p-value of the average Chi-Square: 0.99452\n",
            "Validation Data - Percent of non-significant trees: 37.65%\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}