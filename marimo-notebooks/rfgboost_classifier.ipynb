{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marimo as mo\n",
    "\n",
    "mo.md(\"\"\"\n",
    "# RFGBoost Dashboard üå≥\n",
    "\n",
    "Explore **Random Forest Gradient Boosting**, a hybrid ensemble method combining Random Forests with gradient boosting learning.\n",
    "\"\"\").callout(kind=\"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as scipy_stats\n",
    "from rfgboost import RFGBoost\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    balanced_accuracy_score,\n",
    "    brier_score_loss,\n",
    "    log_loss,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "_ = alt.data_transformers.enable(\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset controls\n",
    "sample_size = mo.ui.slider(500, 15000, value=1000, step=500, label=\"Sample size\")\n",
    "random_seed = mo.ui.number(start=1, stop=999, value=42, label=\"Random seed\")\n",
    "\n",
    "mo.vstack([\n",
    "    mo.md(\"**Dataset Configuration**\"),\n",
    "    mo.hstack([sample_size, random_seed])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_lti(series, special_codes):\n",
    "    \"\"\"Impute mean for non-special codes, keep special codes as-is\"\"\"\n",
    "    # Calculate mean of non-special values\n",
    "    mask = ~np.isin(series, special_codes)\n",
    "    mean_value = series[mask].mean()\n",
    "\n",
    "    return np.where(\n",
    "        np.isin(series, special_codes),\n",
    "        mean_value,\n",
    "        series,\n",
    "    )\n",
    "\n",
    "# Define URL\n",
    "url = \"/Users/deburky/Documents/python/python-ml-projects/random-forest/BankCaseStudyData.csv\"\n",
    "# url = \"https://raw.githubusercontent.com/deburky/boosting-scorecards/refs/heads/main/rfgboost/BankCaseStudyData.csv\"\n",
    "# url = \"https://raw.githubusercontent.com/georgianastasov/credit-bureau-2021-experian/refs/heads/main/score-model/BankCaseStudyData.csv\"\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_csv(url).sample(sample_size.value, random_state=random_seed.value)\n",
    "\n",
    "# Define features and labels\n",
    "label = \"Final_Decision\"\n",
    "dataset[label] = dataset[label].map({\"Decline\": 0, \"Accept\": 1})\n",
    "num_features = [\n",
    "    \"Application_Score\", \"Bureau_Score\", \"Loan_Amount\", \"Time_with_Bank\",\n",
    "    \"Time_in_Employment\", \"Gross_Annual_Income\", \"Loan_to_income\"\n",
    "]\n",
    "cat_features = [\n",
    "    \"Loan_Payment_Frequency\", \"Residential_Status\", \"Cheque_Card_Flag\",\n",
    "    \"Existing_Customer_Flag\", \"Home_Telephone_Number\"\n",
    "]\n",
    "special_codes_lti = [-9999997, -9999998]\n",
    "dataset[\"Loan_to_income\"] = preprocess_lti(dataset[\"Loan_to_income\"], special_codes_lti)\n",
    "\n",
    "# Create train-test split\n",
    "features = cat_features + num_features\n",
    "ix_train = dataset[\"split\"] == \"Development\"\n",
    "ix_test = dataset[\"split\"] == \"Validation\"\n",
    "X_train = dataset.loc[ix_train, features].copy()\n",
    "y_train = dataset.loc[ix_train, label].copy()\n",
    "X_test = dataset.loc[ix_test, features].copy()\n",
    "y_test = dataset.loc[ix_test, label].copy()\n",
    "X_train[cat_features] = X_train[cat_features].astype(str).fillna(\"NA\")\n",
    "X_test[cat_features] = X_test[cat_features].astype(str).fillna(\"NA\")\n",
    "X_train[num_features] = X_train[num_features].fillna(X_train[num_features].median())\n",
    "X_test[num_features] = X_test[num_features].fillna(X_train[num_features].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.sidebar([\n",
    "    mo.md(\"## Model Notebook\"),\n",
    "\n",
    "    mo.md(\"### üìä Loan Approval Dataset\"),\n",
    "    mo.md(f\"\"\"\n",
    "    - **Training samples**: {len(X_train):,}\n",
    "    - **Test samples**: {len(X_test):,}  \n",
    "    - **Features**: {len(num_features)} numeric, {len(cat_features)} categorical\n",
    "    - **Classes**: {len(np.unique(y_train))} (binary)\n",
    "    \"\"\"),\n",
    "\n",
    "    mo.md(\"---\"),\n",
    "\n",
    "    mo.md(\"### üîó Resources\"),\n",
    "    mo.nav_menu({\n",
    "        \"Links\": {\n",
    "            \"https://github.com/deburky\": f\"{mo.icon('lucide:github')} Personal GitHub\",\n",
    "            \"https://github.com/xRiskLab\": f\"{mo.icon('lucide:github')} xRiskLab\",\n",
    "        }\n",
    "    }, orientation=\"vertical\"),\n",
    "\n",
    "    mo.md(\"---\"),\n",
    "    mo.md(\"Built with **marimo** üåäüçÉ\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.vstack([\n",
    "    mo.md(\"### Raw dataset\"),\n",
    "    dataset.head(300),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset selection widget\n",
    "dataset_choice = mo.ui.dropdown(\n",
    "    options=[\"Train\", \"Test\"], \n",
    "    value=\"Train\", \n",
    "    label=\"Select Dataset\"\n",
    ")\n",
    "\n",
    "# Display the choice widget\n",
    "mo.md(f\"### Quick EDA üìä: {dataset_choice}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic data selection based on choice\n",
    "if dataset_choice.value == \"Train\":\n",
    "    X_selected = X_train\n",
    "    y_selected = y_train\n",
    "    dataset_name = \"Train\"\n",
    "else:\n",
    "    X_selected = X_test\n",
    "    y_selected = y_test\n",
    "    dataset_name = \"Test\"\n",
    "\n",
    "# Calculate statistics dynamically\n",
    "label_dist = y_selected.value_counts(normalize=True).reset_index()\n",
    "label_dist.columns = [\"Class\", \"Pct\"]\n",
    "\n",
    "cat_labels = [\"Declined\", \"Approved\"]\n",
    "label_map = {i: label for i, label in enumerate(cat_labels)}\n",
    "label_dist[\"Class\"] = label_dist[\"Class\"].map(label_map)\n",
    "\n",
    "chart_labels = (\n",
    "    alt.Chart(label_dist)\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        x=alt.X(\"Class:N\", title=\"Class\", sort=cat_labels[:-1]),\n",
    "        y=alt.Y(\"Pct:Q\", scale=alt.Scale(domain=[0, 1])),\n",
    "        color=alt.Color(\"Class:N\", scale=alt.Scale(range=[\"#00bfff\", \"#e53935\"]))\n",
    "    )\n",
    "    .properties(title=f\"Class Distribution ({dataset_name})\", width=250)\n",
    ")\n",
    "\n",
    "# Dynamic stats\n",
    "stats_numeric = X_selected.describe().T\n",
    "stats_categorical = X_selected.describe(include=['O']).T\n",
    "\n",
    "# Display everything\n",
    "mo.vstack([\n",
    "    mo.md(f\"### Class distribution ({dataset_name})\"),\n",
    "    mo.ui.altair_chart(chart_labels),\n",
    "    mo.md(f\"### Numeric feature summary ({dataset_name})\"),\n",
    "    mo.plain(stats_numeric),\n",
    "    mo.md(f\"### Categorical feature summary ({dataset_name})\"),\n",
    "    mo.plain(stats_categorical)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYtC",
   "metadata": {},
   "source": [
    "## Interactive ML Model Dashboard üß™\n",
    "\n",
    "We can tune different parameters of the underlying random forests to train a gradient boosting model. In this example we focus on binary classification tasks like credit scoring using [LogitBoost](https://projecteuclid.org/journals/annals-of-statistics/volume-28/issue-2/Additive-logistic-regression--a-statistical-view-of-boosting-With/10.1214/aos/1016218223.full) algorithm formulation.\n",
    "\n",
    "**Algorithm Steps (Classification):**\n",
    "\n",
    "1. **Initialize:** f‚ÇÄ(x) = log(»≥/(1-»≥))\n",
    "\n",
    "2. **For each round m = 1, 2, ..., M:**\n",
    "   - Compute residuals: r·µ¢‚Çò = (y - r·µ¢‚Çò) / (r·µ¢‚Çò(1 - r·µ¢‚Çò))\n",
    "   - Fit Random Forest Regressor h‚Çò(x) on residuals with w = r·µ¢‚Çò(1 - r·µ¢‚Çò)\n",
    "   - Update: f‚Çò(x) = f‚Çò‚Çã‚ÇÅ(x) + Œ∑ ¬∑ h‚Çò(x)\n",
    "\n",
    "3. **Final prediction:** ≈∑(x) = œÉ(f‚Çò(x))\n",
    "\n",
    "**Key Parameters:**\n",
    "\n",
    "- M: Number of boosting rounds\n",
    "- Œ∑: Learning rate\n",
    "- Random Forest depth and pruning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI for model hyperparameters\n",
    "n_estimators = mo.ui.slider(1, 20, value=5, step=1, label=\"Boosting rounds\")\n",
    "random_state = mo.ui.slider(0, 123, value=42, step=1, label=\"Random seed\")\n",
    "trees_in_rf = mo.ui.slider(1, 20, value=5, step=1, label=\"Trees per forest\")\n",
    "learning_rate = mo.ui.slider(0.1, 2.0, value=0.5, step=0.1, label=\"Learning rate\")\n",
    "max_depth = mo.ui.slider(2, 10, value=5, step=1, label=\"Max tree depth\")\n",
    "ccp_alpha = mo.ui.slider(0.0, 0.4, value=0.0, step=0.05, label=\"Regularization\")\n",
    "\n",
    "mo.vstack([\n",
    "    mo.md(\"### RFGBoost hyperparameters üé≤\"),\n",
    "    mo.hstack([n_estimators, trees_in_rf, learning_rate]),\n",
    "    mo.hstack([max_depth, ccp_alpha, random_state])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RFGBoost(\n",
    "    n_estimators=n_estimators.value,\n",
    "    rf_params={\n",
    "        \"n_estimators\": trees_in_rf.value,\n",
    "        \"max_depth\": max_depth.value,\n",
    "        \"random_state\": 42,\n",
    "        \"ccp_alpha\": ccp_alpha.value,\n",
    "    },\n",
    "    learning_rate=learning_rate.value,\n",
    "    cat_features=cat_features,\n",
    "    task=\"classification\",\n",
    ")\n",
    "_ = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_train_prob = model.predict_proba(X_train)\n",
    "if y_train_prob.ndim > 1: \n",
    "    y_train_prob = y_train_prob[:, 1]\n",
    "train_acc = accuracy_score(y_train, y_train_prob > 0.5)\n",
    "train_auc = roc_auc_score(y_train, y_train_prob)\n",
    "train_logloss = log_loss(y_train, y_train_prob)\n",
    "train_brier = brier_score_loss(y_train, y_train_prob)\n",
    "train_bacc = balanced_accuracy_score(y_train, y_train_prob > 0.5)\n",
    "train_aucpr = average_precision_score(y_train, y_train_prob)\n",
    "\n",
    "y_test_prob = model.predict_proba(X_test)\n",
    "if y_test_prob.ndim > 1: \n",
    "    y_test_prob = y_test_prob[:, 1]\n",
    "test_acc = accuracy_score(y_test, y_test_prob > 0.5)\n",
    "test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "test_logloss = log_loss(y_test, y_test_prob)\n",
    "test_brier = brier_score_loss(y_test, y_test_prob)\n",
    "test_bacc = balanced_accuracy_score(y_test, y_test_prob > 0.5)\n",
    "test_aucpr = average_precision_score(y_test, y_test_prob)\n",
    "gap = test_logloss - train_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"Set\": \"Train\",\n",
    "            \"LogLoss\": train_logloss,\n",
    "            \"BrierLoss\": train_brier,\n",
    "            \"AUC\": train_auc,\n",
    "            \"Accuracy\": train_acc,\n",
    "            \"BalancedAccuracy\": train_bacc,\n",
    "            \"PR-AUC\": train_aucpr\n",
    "        },\n",
    "        {\n",
    "            \"Set\": \"Test\",\n",
    "            \"LogLoss\": test_logloss,\n",
    "            \"BrierLoss\": test_brier,\n",
    "            \"AUC\": test_auc,\n",
    "            \"Accuracy\": test_acc,\n",
    "            \"BalancedAccuracy\": test_bacc,\n",
    "            \"PR-AUC\": test_aucpr\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ Line plots ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "line_chart_neg_better = (\n",
    "    alt.Chart(perf_df)\n",
    "    .transform_fold([\"LogLoss\", \"BrierLoss\"], as_=[\"Metric\", \"Value\"])\n",
    "    .mark_line(point=True, strokeWidth=3)\n",
    "    .encode(\n",
    "        x=alt.X(\"Metric:N\", axis=alt.Axis(title=\"Metrics\"), sort=[\"LogLoss\", \"BrierLoss\"]),\n",
    "        y=alt.Y(\"Value:Q\", axis=alt.Axis(title=\"Value\")),\n",
    "        color=alt.Color(\n",
    "            \"Set:N\", scale=alt.Scale(range=[\"dodgerblue\", \"red\"]),\n",
    "            legend=alt.Legend(orient=\"none\", legendX=10, legendY=250)\n",
    "        ),\n",
    "        tooltip=[\"Set:N\", \"Metric:N\", \"Value:Q\"],\n",
    "    )\n",
    "    .properties(width=400, height=300, title=\"Proper Scoring Metrics (lower is better)\")\n",
    ")\n",
    "\n",
    "line_chart_pos_better = (\n",
    "    alt.Chart(perf_df)\n",
    "    .transform_fold([\"AUC\", \"PR-AUC\", \"Accuracy\", \"BalancedAccuracy\"], as_=[\"Metric\", \"Value\"])\n",
    "    .mark_line(point=True, strokeWidth=0)\n",
    "    .encode(\n",
    "        x=alt.X(\"Metric:N\", axis=alt.Axis(title=\"Metrics\"), sort=[\"AUC\", \"PR-AUC\", \"Accuracy\", \"BalancedAccuracy\"]),\n",
    "        y=alt.Y(\"Value:Q\", axis=alt.Axis(title=\"Value\")),\n",
    "        color=alt.Color(\n",
    "            \"Set:N\", scale=alt.Scale(range=[\"dodgerblue\", \"red\"]),\n",
    "            legend=alt.Legend(orient=\"none\", legendX=10, legendY=250)\n",
    "        ),\n",
    "        tooltip=[\"Set:N\", \"Metric:N\", \"Value:Q\"],\n",
    "    )\n",
    "    .properties(width=400, height=300, title=\"Metrics (higher is better)\")\n",
    ")\n",
    "\n",
    "# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ Feature importance ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "feat_imp = model.get_feature_importance()\n",
    "if not isinstance(feat_imp, pd.DataFrame):\n",
    "    feat_imp = pd.DataFrame(list(feat_imp.items()), columns=[\"Feature\", \"Importance\"])\n",
    "feat_imp = feat_imp.sort_values(\"Importance\", ascending=False)\n",
    "chart_feat = alt.Chart(feat_imp).mark_bar().encode(\n",
    "    x=alt.X(\"Importance:Q\"),\n",
    "    color=alt.Color(\"Importance:Q\", scale=alt.Scale(scheme=\"tealblues\")),\n",
    "    y=alt.Y(\"Feature:N\", sort=\"-x\"),\n",
    "    tooltip=[\"Feature\", \"Importance\"]\n",
    ").properties(width=400, height=300, title=\"Feature Importances\")\n",
    "\n",
    "# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ Bar charts ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "logloss_chart = (\n",
    "    alt.Chart(perf_df)\n",
    "        .mark_bar(size=50)\n",
    "        .encode(x=\"Set:N\", y=\"LogLoss:Q\")\n",
    "        .properties(width=120, title=\"Log Loss\")\n",
    ")\n",
    "auc_chart = (\n",
    "    alt.Chart(perf_df).mark_bar(size=50).encode(x=\"Set:N\", y=alt.Y(\"AUC:Q\", scale=alt.Scale(domain=[0, 1]))).properties(width=120, title=\"AUC\")\n",
    ")\n",
    "\n",
    "# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ Overfitting gap ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "gap_df = pd.DataFrame({\"Type\": [\"Overfit Gap\"], \"Gap\": [gap]})\n",
    "gap_chart = (\n",
    "    alt.Chart(gap_df)\n",
    "    .mark_bar(\n",
    "        width=30,\n",
    "        color=alt.expr(\"abs(datum.Gap) > 0.1 ? 'red' : abs(datum.Gap) > 0.05 ? 'orange' : 'palegreen'\"),\n",
    "    )\n",
    "    .encode(\n",
    "        x=alt.X(\"Type:N\", axis=None),\n",
    "        y=alt.Y(\"Gap:Q\", axis=alt.Axis(format=\".3f\")),\n",
    "        tooltip=[\"Gap:Q\"],\n",
    "    )\n",
    "    .properties(width=80, height=150, title=\"Overfit Level\")\n",
    ")\n",
    "\n",
    "# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ Combine plots ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "left_panel = alt.vconcat(\n",
    "    line_chart_pos_better,  chart_feat\n",
    ")\n",
    "right_panel = alt.vconcat(\n",
    "    line_chart_neg_better,\n",
    "    alt.hconcat(gap_chart, logloss_chart, auc_chart)\n",
    ")\n",
    "layout_option3 = left_panel | right_panel\n",
    "mo.ui.altair_chart(layout_option3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nWHF",
   "metadata": {},
   "source": [
    "## 2D feature map model decision surface üóæ\n",
    "\n",
    "Below we plot a 2D scatterplot with model predicted probabilities to show confidence of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection for next plots\n",
    "feature_x = mo.ui.dropdown(options=num_features, value=num_features[0], label=\"X-axis feature\")\n",
    "feature_y = mo.ui.dropdown(options=[f for f in num_features if f != num_features[0]], value=num_features[1], label=\"Y-axis feature\")\n",
    "mo.hstack([feature_x, feature_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 2D model reactively when features change\n",
    "selected_features = [feature_x.value, feature_y.value]\n",
    "\n",
    "model_2d = RFGBoost(\n",
    "    n_estimators=n_estimators.value,\n",
    "    rf_params={\"max_depth\": max_depth.value, \"random_state\": 42, \"ccp_alpha\": ccp_alpha.value},\n",
    "    learning_rate=learning_rate.value,\n",
    "    cat_features=[cat for cat in cat_features if cat in selected_features],  # Only relevant cat features\n",
    "    task=\"classification\"\n",
    ")\n",
    "\n",
    "# Fit the model on just the selected 2D features\n",
    "_ = model_2d.fit(X_train[selected_features], y_train)\n",
    "\n",
    "print(f\"2D model trained on features: {', '.join(selected_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_conf = mo.ui.checkbox(True, label=\"Show confidence\")\n",
    "resolution = mo.ui.slider(20, 100, value=50, step=10, label=\"Resolution\")\n",
    "mo.hstack([show_conf, resolution])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define consistent colors for classes\n",
    "class_colors = [\"#d73027\", \"#4575b4\"]  # Red for class 0, Blue for class 1\n",
    "\n",
    "plot_df = X_test.copy()\n",
    "plot_df[\"y_true\"] = y_test\n",
    "\n",
    "# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ Correlation metrics ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "xi, _ = scipy_stats.chatterjeexi(plot_df[feature_x.value], plot_df[feature_y.value])\n",
    "rho, _ = scipy_stats.spearmanr(plot_df[feature_x.value], plot_df[feature_y.value])\n",
    "\n",
    "# Use the 2D model with 2D test data\n",
    "X_test_2d = X_test[[feature_x.value, feature_y.value]]\n",
    "y_raw_prob = model_2d.predict_proba(X_test_2d)[:, 1]\n",
    "\n",
    "auc_score = roc_auc_score(\n",
    "    y_test, y_raw_prob\n",
    ")\n",
    "bacc_score = balanced_accuracy_score(\n",
    "    y_test, (y_raw_prob > 0.5).astype(int)\n",
    ")\n",
    "\n",
    "y_prob = np.column_stack(\n",
    "    (\n",
    "        1 - model_2d.predict_ci(X_test_2d)[:, 0],  # Upper bound for P(class=0)\n",
    "        model_2d.predict_ci(X_test_2d)[:, 1],      # Upper bound for P(class=1)\n",
    "    )\n",
    ")\n",
    "# y_prob_scatter = y_prob\n",
    "y_prob_scatter = y_prob[np.arange(len(y_test)), y_test]\n",
    "plot_df[\"y_prob\"] = y_prob_scatter\n",
    "\n",
    "# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ Scatter 2D ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "scatter_chart = (\n",
    "    alt.Chart(plot_df)\n",
    "    .mark_circle(size=60, opacity=0.8, stroke=\"white\", strokeWidth=1)\n",
    "    .encode(\n",
    "        x=alt.X(feature_x.value + \":Q\", title=feature_x.value).scale(zero=False),\n",
    "        y=alt.Y(feature_y.value + \":Q\", title=feature_y.value).scale(zero=False),\n",
    "        color=alt.Color(\n",
    "            \"y_prob:Q\",\n",
    "            scale=alt.Scale(domain=[\"0\", \"1\"], range=class_colors),\n",
    "            legend=alt.Legend(title=\"Model Confidence\"),\n",
    "        ),\n",
    "        shape=alt.Shape(\"y_true:N\", scale=alt.Scale(range=[\"circle\", \"square\"]), legend=alt.Legend(title=\"True Label\")),\n",
    "        tooltip=[feature_x.value, feature_y.value, \"y_true\", \"y_prob\"],\n",
    "    )\n",
    "    .properties(\n",
    "        width=350,\n",
    "        height=300,\n",
    "        title=alt.Title(\"Scatterplot\", subtitle=[f\"Chatterjee xi = {xi:.3f}\", f\"Spearman œÅ = {rho:.3f}\"]),\n",
    "    )\n",
    ")\n",
    "\n",
    "# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ Decision surface ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "x_feature = feature_x.value\n",
    "y_feature = feature_y.value\n",
    "x_min, x_max = X_train[x_feature].min() - 1, X_train[x_feature].max() + 1\n",
    "y_min, y_max = X_train[y_feature].min() - 1, X_train[y_feature].max() + 1\n",
    "res = resolution.value\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, res), np.linspace(y_min, y_max, res))\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "grid_2d = pd.DataFrame(grid, columns=[x_feature, y_feature])\n",
    "Z = model_2d.predict_proba(grid_2d)\n",
    "if Z.ndim > 1:\n",
    "    Z = Z[:, 1]\n",
    "\n",
    "contour_df = pd.DataFrame({\"x\": xx.ravel(), \"y\": yy.ravel(), \"prob\": Z})\n",
    "\n",
    "# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ Confidence levels ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "if show_conf.value:\n",
    "    decision_surface = (\n",
    "        alt.Chart(contour_df)\n",
    "        .mark_square(size=(350 * 500) / (res * res), opacity=0.7)\n",
    "        .encode(\n",
    "            x=alt.X(\"x:Q\", title=x_feature).scale(zero=False),\n",
    "            y=alt.Y(\"y:Q\", title=y_feature).scale(zero=False),\n",
    "            color=alt.Color(\n",
    "                \"prob:Q\",\n",
    "                scale=alt.Scale(domain=[0, 1], range=class_colors),\n",
    "                legend=alt.Legend(title=\"P(y=1)\"),\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    decision_surface = (\n",
    "        alt.Chart(contour_df[abs(contour_df.prob - 0.5) < 0.05])\n",
    "        .mark_circle(size=8, color=\"black\")\n",
    "        .encode(\n",
    "            x=alt.X(\"x:Q\", title=x_feature).scale(zero=False),\n",
    "            y=alt.Y(\"y:Q\", title=y_feature).scale(zero=False)\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Training points\n",
    "tdf = pd.DataFrame({x_feature: X_train[x_feature], y_feature: X_train[y_feature], \"Class\": y_train.astype(str)})\n",
    "\n",
    "training_points = (\n",
    "    alt.Chart(tdf)\n",
    "    .mark_circle(size=50, opacity=0.9, stroke=\"white\", strokeWidth=1)\n",
    "    .encode(\n",
    "        x=f\"{x_feature}:Q\",\n",
    "        y=f\"{y_feature}:Q\",\n",
    "        color=alt.Color(\n",
    "            \"Class:N\", scale=alt.Scale(domain=[\"0\", \"1\"], range=class_colors), legend=alt.Legend(title=\"True Class\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "decision_chart = (decision_surface + training_points).properties(\n",
    "    width=350, height=300, title=alt.Title(\"Decision surface\", subtitle=[f\"AUC = {auc_score:.3f}\", f\"Balanced Accuracy = {bacc_score:.3f}\"])\n",
    ")\n",
    "\n",
    "\n",
    "# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ Combined plot ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "combined_chart = (scatter_chart | decision_chart).resolve_scale(color=\"independent\")\n",
    "\n",
    "mo.ui.altair_chart(combined_chart)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
