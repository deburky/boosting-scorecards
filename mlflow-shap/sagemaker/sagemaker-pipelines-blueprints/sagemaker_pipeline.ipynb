{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9161c0f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# SageMaker Pipeline Blueprint\n",
    "\n",
    "⚠️ **IMPORTANT: This notebook contains EXAMPLE/PLACEHOLDER credentials only.**\n",
    "\n",
    "All AWS account IDs (497487485332), ARNs, security groups, and other sensitive-looking values are fictional examples. Replace them with your actual AWS resources before use.\n",
    "\n",
    "See `SECURITY.md` for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b2dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterFloat,\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import CacheConfig, ProcessingStep, TrainingStep\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# ⚠️ REPLACE ALL VALUES BELOW WITH YOUR ACTUAL AWS RESOURCES\n",
    "# These are EXAMPLE/PLACEHOLDER values only!\n",
    "\n",
    "region = \"us-east-1\"  # Your AWS region\n",
    "role = \"arn:aws:iam::497487485332:role/service-role/AmazonSageMaker-ExecutionRole\"  # EXAMPLE - Replace with your IAM role\n",
    "bucket = \"my-s3-bucket\"  # EXAMPLE - Replace with your S3 bucket\n",
    "base_prefix = \"data\"\n",
    "job_id = f\"pipe-{datetime.now().strftime('%Y%m%d%H%M')}\"\n",
    "\n",
    "# MLflow configuration (if using SageMaker MLflow tracking server)\n",
    "mlflow_tracking_uri = \"arn:aws:sagemaker:us-east-1:497487485332:mlflow-tracking-server/sagemaker-mlflow-3\"  # EXAMPLE - Replace with your tracking server\n",
    "mlflow_bucket = \"sagemaker-us-east-1-497487485332\"  # EXAMPLE - Replace with your bucket\n",
    "mlflow_experiment_path = \"mlflow-experiments-3/1\"\n",
    "\n",
    "# Create SageMaker session\n",
    "sm_session = sagemaker.Session(boto3.Session(region_name=region))\n",
    "\n",
    "# KMS key for encryption (optional)\n",
    "kms_key = \"arn:aws:kms:us-east-1:497487485332:key/1234abcd-12ab-34cd-56ef-1234567890ab\"  # EXAMPLE - Replace with your KMS key\n",
    "\n",
    "# Security groups (EXAMPLE - Replace with your VPC resources)\n",
    "network_config = NetworkConfig(\n",
    "    security_group_ids=[\"sg-a9e76d60e03a174ff\"],  # EXAMPLE security group\n",
    "    subnets=[\n",
    "        \"subnet-f28751aa8ad2ad51a\",  # EXAMPLE subnet\n",
    "        \"subnet-0a26e0df316b74f23\",  # EXAMPLE subnet\n",
    "        \"subnet-ccca708d00e55a2bb\",  # EXAMPLE subnet\n",
    "    ],\n",
    ")\n",
    "cache_config = CacheConfig(\n",
    "    enable_caching=True,\n",
    "    expire_after=\"1 day\",\n",
    ")\n",
    "\n",
    "# Pipeline parameters\n",
    "model_version = ParameterString(name=\"ModelVersion\", default_value=\"v1.1d\")\n",
    "date_filter = ParameterString(\n",
    "    name=\"DateFilter\", default_value=\"reporting_qdate = DATE '2025-01-01'\"\n",
    ")\n",
    "test_size = ParameterFloat(name=\"TestSize\", default_value=0.3)\n",
    "sampling_ratio = ParameterFloat(name=\"SamplingRatio\", default_value=0.1)\n",
    "iterations = ParameterInteger(name=\"Iterations\", default_value=357)\n",
    "learning_rate = ParameterFloat(name=\"LearningRate\", default_value=0.13)\n",
    "depth = ParameterInteger(name=\"Depth\", default_value=4)\n",
    "early_stop_rounds = ParameterInteger(name=\"EarlyStopRounds\", default_value=43)\n",
    "instance_type = ParameterString(name=\"InstanceType\", default_value=\"ml.m6i.8xlarge\")\n",
    "instance_count = ParameterInteger(name=\"InstanceCount\", default_value=4)\n",
    "batch_size = ParameterInteger(name=\"BatchSize\", default_value=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2926a25",
   "metadata": {},
   "source": [
    "## Data Preparation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0cdd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep = ProcessingStep(\n",
    "    name=\"DataPreparation\",\n",
    "    processor=ScriptProcessor(\n",
    "        command=[\"python3\"],\n",
    "        image_uri=\"497487485332.dkr.ecr.us-east-1.amazonaws.com/catboost-mlflow-3-container:latest\",\n",
    "        role=role,\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.m6i.16xlarge\",\n",
    "        sagemaker_session=sm_session,\n",
    "    ),\n",
    "    code=\"../data_preparation.py\",\n",
    "    job_arguments=[\n",
    "        \"--bucket\",\n",
    "        bucket,\n",
    "        \"--base_prefix\",\n",
    "        base_prefix,\n",
    "        \"--out_prefix\",\n",
    "        f\"{base_prefix}/ml-dataset\",\n",
    "        \"--crawler_name\",\n",
    "        \"ML_DATASET\",\n",
    "        \"--custom_date_filter\",\n",
    "        date_filter,\n",
    "        \"--run-glue-job\",\n",
    "        \"--test-size\",\n",
    "        test_size.to_string(),\n",
    "        \"--sampling-ratio\",\n",
    "        sampling_ratio.to_string(),\n",
    "        \"--output-prefix\",\n",
    "        f\"{base_prefix}/ml-dataset-stratified/{job_id}\",\n",
    "        \"--job-id\",\n",
    "        job_id,\n",
    "    ],\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a380a1ce",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc514045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the estimator\n",
    "estimator = Estimator(\n",
    "    image_uri=\"497487485332.dkr.ecr.us-east-1.amazonaws.com/catboost-mlflow-3-container:latest\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m6i.32xlarge\",\n",
    "    sagemaker_session=sm_session,\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"../\",\n",
    "    environment={\"MLFLOW_TRACKING_URI\": mlflow_tracking_uri},\n",
    "    output_path=f\"s3://{bucket}/{base_prefix}/ml-artifacts\",\n",
    ")\n",
    "# Set the hyperparameters exactly as train.py expects them\n",
    "estimator.set_hyperparameters(\n",
    "    model_version=model_version,\n",
    "    iterations=iterations,\n",
    "    learning_rate=learning_rate,\n",
    "    depth=depth,\n",
    "    early_stopping_rounds=early_stop_rounds,\n",
    ")\n",
    "\n",
    "# Create the TrainingStep\n",
    "training = TrainingStep(\n",
    "    name=\"ModelTraining\",\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=f\"s3://{bucket}/{base_prefix}/ml-dataset-stratified/{job_id}/train\",\n",
    "            content_type=\"application/x-parquet\",\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "            s3_data=f\"s3://{bucket}/{base_prefix}/ml-dataset-stratified/{job_id}/test\",\n",
    "            content_type=\"application/x-parquet\",\n",
    "        ),\n",
    "    },\n",
    "    depends_on=[data_prep],\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066a7363",
   "metadata": {},
   "source": [
    "## Inference Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d02e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = ProcessingStep(\n",
    "    name=\"BatchInference\",\n",
    "    processor=ScriptProcessor(\n",
    "        command=[\"python3\"],\n",
    "        image_uri=\"497487485332.dkr.ecr.us-east-1.amazonaws.com/ray-inference-container:latest\",\n",
    "        role=role,\n",
    "        instance_count=4,\n",
    "        instance_type=\"ml.m6i.8xlarge\",\n",
    "        volume_size_in_gb=100,\n",
    "        sagemaker_session=sm_session,\n",
    "        env={\"MLFLOW_TRACKING_URI\": mlflow_tracking_uri},\n",
    "        output_kms_key=kms_key,  # for SSE encryption\n",
    "    ),\n",
    "    code=\"../batch_inference.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=f\"s3://{bucket}/{base_prefix}/ml-dataset\",\n",
    "            destination=\"/opt/ml/processing/input\",\n",
    "        ),\n",
    "        ProcessingInput(  # model.tar.gz from training step\n",
    "            source=training.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model-artifacts\",\n",
    "        ),\n",
    "        ProcessingInput(  # output.tar.gz (MLflow metadata + model info)\n",
    "            source=Join(\n",
    "                on=\"\",\n",
    "                values=[\n",
    "                    f\"s3://{bucket}/{base_prefix}/ml-artifacts/\",\n",
    "                    training.properties.TrainingJobName,\n",
    "                    \"/output/\",\n",
    "                ],\n",
    "            ),\n",
    "            destination=\"/opt/ml/processing/mlflow\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"inference_results\",\n",
    "            source=\"/opt/ml/processing/output\",\n",
    "            destination=f\"s3://{bucket}/{base_prefix}/outputs/inference/{job_id}\",\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"inference_metadata\",\n",
    "            source=\"/opt/ml/processing/output_metadata\",\n",
    "            destination=f\"s3://{bucket}/{base_prefix}/outputs/inference/{job_id}/metadata\",\n",
    "        ),\n",
    "    ],\n",
    "    job_arguments=[\n",
    "        \"--data-path\",\n",
    "        \"/opt/ml/processing/input\",\n",
    "        \"--mlflow-metadata\",\n",
    "        \"/opt/ml/processing/mlflow\",\n",
    "        \"--model-version\",\n",
    "        model_version,\n",
    "        \"--output-path\",\n",
    "        \"/opt/ml/processing/output\",\n",
    "        \"--region\",\n",
    "        region,\n",
    "        \"--bucket\",\n",
    "        bucket,\n",
    "        \"--glue-crawler\",\n",
    "        \"BATCH_INFERENCE\",\n",
    "        \"--glue-database\",\n",
    "        \"scoring_service\",\n",
    "        \"--glue-table\",\n",
    "        \"model_scores_aud\",\n",
    "    ],\n",
    "    depends_on=[training],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5963467",
   "metadata": {},
   "source": [
    "## Load Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94745da",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = ProcessingStep(\n",
    "    name=\"RedshiftLoad\",\n",
    "    processor=ScriptProcessor(\n",
    "        command=[\"python3\"],\n",
    "        image_uri=\"497487485332.dkr.ecr.us-east-1.amazonaws.com/ray-inference-container:latest\",\n",
    "        role=role,\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.m6i.large\",\n",
    "        sagemaker_session=sm_session,\n",
    "        env={\"AWS_DEFAULT_REGION\": region},\n",
    "        network_config=network_config,\n",
    "    ),\n",
    "    code=\"../s3_to_redshift.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=inference.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"inference_metadata\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/metadata\",\n",
    "        )\n",
    "    ],\n",
    "    job_arguments=[\n",
    "        \"--metadata-path\",\n",
    "        \"/opt/ml/processing/metadata/metadata.json\",\n",
    "        \"--redshift-schema\",\n",
    "        \"scoring_service\",\n",
    "        \"--redshift-table\",\n",
    "        \"model_scores_aud\",\n",
    "        \"--redshift-iam-role\",\n",
    "        \"arn:aws:iam::497487485332:role/AWSGlueServiceRoleDefault\",\n",
    "        \"--job-name\",\n",
    "        f\"redshift-load-job-{job_id}\",\n",
    "    ],\n",
    "    depends_on=[inference],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e45bc93",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c253022",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=f\"mlflow-training-pipeline-{job_id}\",\n",
    "    parameters=[\n",
    "        model_version,\n",
    "        date_filter,\n",
    "        test_size,\n",
    "        sampling_ratio,\n",
    "        iterations,\n",
    "        learning_rate,\n",
    "        depth,\n",
    "        early_stop_rounds,\n",
    "        instance_type,\n",
    "        instance_count,\n",
    "        batch_size,\n",
    "    ],\n",
    "    steps=[data_prep, training, inference, load],\n",
    "    sagemaker_session=sm_session,\n",
    ")\n",
    "\n",
    "# Create or update the pipeline\n",
    "pipeline.upsert(role_arn=role)\n",
    "\n",
    "# Start pipeline execution using default parameters\n",
    "execution = pipeline.start()\n",
    "\n",
    "print(f\"✅ Pipeline started: {execution.arn}\")\n",
    "print(\"Monitor execution in SageMaker Studio or via AWS Console\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
